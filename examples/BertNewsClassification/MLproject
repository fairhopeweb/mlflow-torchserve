name: bert-classification

conda_env: conda.yaml

entry_points:
  main:
    parameters:
      max_epochs: {type: int, default: 1}
      num_train_samples: {type:int, default: 200}
      num_test_samples: {type:int, default: 200}
      vocab_file: {type: str, default: 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt'}
      model_save_path: {type: str, default: 'models'}

    command: |
          python news_classifier.py \
            --max_epochs {max_epochs} \
            --num_train_samples {num_train_samples} \
            --num_test_samples {num_test_samples} \
            --vocab_file {vocab_file} \
            --model_save_path {model_save_path}
